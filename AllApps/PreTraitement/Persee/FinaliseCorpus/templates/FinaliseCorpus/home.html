<!DOCTYPE html>
<html lang="fr">

{% load static %}

<head>
    <meta charset="UTF-8">

    {% load static %}

    <title>Evaluation Home</title>
    <style>
        .marge {
            margin-left: 3em;}
        .marge2 {
            margin-left: 6em;}
        .marge3 {
            margin-left: 9em;}
        .suite {
            font-style: italic;
            text-align: right;}
        .present {
            text-decoration: underline;
            font-weight:bold;}
        .a {
            text-align: center;}
        .cite {
            text-align: justify;
            margin-right: 9em;
            margin-left: 9em;
            font-size: 0.9em;}
        .note {
            text-decoration: none;
            }
        p {
            text-align: justify;}
        h1 {
            text-align: center;}
        h2 {
            margin-left: 3em;
            margin-top: 1.5em;
            margin-bottom: 1.5em;}
        h3 {
            margin-left: 6em;
            margin-top: 1.5em;
            margin-bottom: 1.5em;}
        h4 {
            margin-left: 9em;
            margin-top: 1.5em;
            margin-bottom: 1.5em;}
        li {
            margin-left: 3em;
            margin-top:15px;
            text-align: justify;}

        .fraction {
            display: inline-block;		/* pour que la fraction soit un élément de la ligne */
            vertical-align: middle;
            }

        .fraction span {
            display: block;				/* les blocks se placent par défaut les uns sous les autres */
            padding-top: 0.15em;
            text-align: center;
            }

        .fraction span.denominateur {
            border-top: 1px solid black; /* la barre de fraction */
            }

        table{
          border-collapse: collapse;
          margin: auto;
        }

        td{
          border: 1px solid black;
          padding: 10px;
          text-align :center;
        }
        div.a {
                text-align: center;
                padding-top: 15px;}

    </style>
</head>
<body>

<p class="suite"> Retour :
    <a  href="{% url 'general:home' %}">Page d'accueil</a>
</p>
<br>


    <h1>Chapitre 6 : Finalisation et évaluation des corpus d’étude </h1>

    <br>
    <br>

<p class="present">Plan du chapitre :</p>


 <a class="marge" id="I-ref" href="#I">I) Finalisation des corpus d’étude</a>
<br>
<br>
    <a class="marge2" id="I1-ref" href="#I1">1)	Ajout et retrait de documents</a>
<br>
<br>
    <a class="marge2" id="I2-ref" href="#I2">2) Choix, améliorations et limites des prétraitements
        effectués</a>
<br>
<br>
        <a class="marge3" id="I2a-ref" href="#I2a">a) Réflexions et choix des prétraitements</a>
<br>
<br>

        <a class="marge3" id="I2b-ref" href="#I2b">b) Amélioration des dictionnaires et des prétraitements</a>

        {% if user.is_superuser %}
            <br>
            <a class="marge3" href="{% url 'FinaliseCorpus:AmeliorPretrait' %}"> Accès Form
                Amelior Prerrait </a>
        {% endif %}
<br>
<br>
        <a class="marge3" id="I2c-ref" href="#I2c">c) Réalisation et limite des prétraitements effectués</a>

        {% if user.is_superuser %}
            <br>
            <a class="marge3" href="{% url 'FinaliseCorpus:AppliEtLimitPretrait' %}"> Accès Form
                AppliEtLimitePretrait </a>
        {% endif %}

<br>
<br>
<a class="marge" id="II-ref" href="#II">II)	Évaluation des corpus d’étude </a>

    {% if user.is_superuser %}
            <br>
            <a class="marge" href="{% url 'EvaluateCorpus:home' %}"> Accès Form
                Evaluate Corpus </a>
        {% endif %}

<br>
<br>
<a class="marge" id="III-ref" href="#III">III) Réflexions conclusives </a>

<br>
<br>
<br>

    <p class="present">Texte du chapitre</p>



<h2 id="I">I) Finalisation des corpus d’étude <a href="#I-ref">&#8617;</a> </h2>

    <p class="mypara">
    <span class="marge">
    L'étape de finalisation des corpus est constituée de deux moments :
    </span>
    </p>

    <ul>
    <li> L’ajout et le retrait de documents par rapport aux corpus jusqu’ici construits </li>
	<li> Les choix concernant tout un ensemble de prétraitements terminaux : segmentation,
        lemmatisation et suppression de mots-outils </li>
    </ul>

<h3 id="I1">1) Ajout et retrait de documents <a href="#I1-ref">&#8617;</a> </h3>


    <p class="mypara"> <span class="marge">	Cette phase de travail est due tout d’abord à la volonté d’intégrer
    les quelques documents dont l’UAR <em>Persée</em> a limité l’accès (<em>cf.</em> section <a
            href="{% url 'DelimitCorpus:home' %}#III6">Chap4.III.6</a>). Ces documents
    ont été scannés et océrisés avec l’aide de la MSH Lyon St-Étienne, puis corrigés et compilés dans deux
        fichiers : un premier pour compléter le corpus
    « Article »<sup><a id="fn1-ref" class="note" href="#fn1">1</a></sup>, un deuxième pour le corpus
    « ArticlePlusCr »<sup><a id="fn2-ref" class="note" href="#fn2">2</a></sup>. Les textes obtenus sont de
        meilleure qualité que ceux issus de l’UAR <em>Persée</em> car ils ont été océrisés avec un logiciel
        plus récent et
    corrigés manuellement<sup><a id="fn3-ref" class="note" href="#fn3">3</a></sup>. La présence de
        plusieurs articles de
    deux auteurs mobilisés par Olivier Orain dans sa thèse, Antoine S. Bailly et Jean-Bernard Racine, a
    joué un rôle dans le choix d’intégrer ces textes malgré l’hétérogénéité constatée. Pour rester cohérent
    par rapport à la construction précédemment menée
        (<em>cf.</em> section Manuscrit Chap2.II.5.a)<sup><a id="fn4-ref" class="note" href="#fn4">4</a></sup>,
        l’ajout ne s’est pas limité à ces deux auteurs. Il a
    concerné l’ensemble des documents qui auraient fait partie du corpus sans ces limitations d’accès
    .</span></p>

    <div id="languedetect"><p class="mypara"> <span class="marge">	Symétriquement, le retrait de
    certains documents s'est imposé après l’observation d’articles en anglais dans les corpus créés malgré
        le travail précédemment effectué sur
    la métadonnée ‘Langue’ (<em>cf.</em> section <a href="{% url 'DelimitCorpus:home' %}#III5">Chap4.III.5</a>). Une
    expérimentation a été réalisée en soumettant les textes précédemment obtenus à un algorithme de
    détection de langue existant en
        <em>Python</em><sup><a id="fn5-ref" class="note" href="#fn5">5</a></sup>. Les
        résultats suivants (<a href="{% url 'FinaliseCorpus:LangueDetectFct' 'Article' %}" >@ArticleDetectLang</a> et
        <a href="{% url 'FinaliseCorpus:LangueDetectFct' 'ArticlePlusCr' %}" >@ArticlePlusCrDetectLang</a>)
        présentent tous les cas où la langue détectée par l’algorithme n’est
    pas le français. Une vérification manuelle a permis de confirmer que les résultats obtenus étaient
    exacts. Il y a donc des erreurs sur la métadonnée « Langue » renseignée par l’UAR <em>Persée</em> pour
    ces documents. À la suite de cette exploration, ils ont été retirés des corpus créés.</span></p></div>

    <div id="addremove"><p class="mypara"> <span class="marge">	Les deux corpus
    « ArticleComplet » et « ArticlePlusCrComplet » ont été ainsi
        constitués<sup><a id="fn6-ref" class="note" href="#fn6">6</a></sup>.</span></p>

    <p class="mypara"> <span class="marge">	Après cette étape, de nombreuses questions se sont posées
    concernant des prétraitements classiques (mais toujours discutés) dans les pratiques d’analyse
        textuelle : niveau de segmentation, lemmatisation, suppression des mots-outils.</span></p></div>


<h3 id="I2">2) Choix, améliorations et limites des prétraitements effectués <a href="#I2-ref">&#8617;</a>
</h3>

<h4 id="I2a">a) Réflexions et choix des prétraitements <a href="#I2a-ref">&#8617;</a> </h4>


    <div id="Laf1"><p class="mypara"> <span class="marge">	Pour
    chaque prétraitement, le choix à réaliser ne se résume pas à une alternative entre deux possibilités mais présente de
    multiples variantes. Par exemple, la segmentation des
textes en unités distinctes (servant ensuite comme base dans les traitements) est réalisable à
différents niveaux : la forme
    graphique<sup><a id="fn7-ref" class="note" href="#fn7">7</a></sup>, le mot, le mot composé (avec des
        différences existantes de degrés entre ceux se limitant aux composés à
        apostrophe<sup><a id="fn8-ref" class="note" href="#fn8">8</a></sup>
        et à trait d’union<sup><a id="fn9-ref" class="note" href="#fn9">9</a></sup> et ceux prenant aussi en
    compte des composés détachés<sup><a id="fn10-ref" class="note" href="#fn10">10</a></sup>) ou encore la
        sélection des n-gram<sup><a id="fn11-ref" class="note" href="#fn11">11</a></sup> les plus
        fréquents… Au niveau de la
    lemmatisation<sup><a id="fn12-ref" class="note" href="#fn12">12</a></sup>, il existe une controverse
        depuis les années 1980 sur la pertinence de ce prétraitement (<a
                href="{% url 'Biblio:ViewBiblioInterface' 0 %}#Laf1">Lafon 1984</a>; 
        <a href="{% url 'Biblio:ViewBiblioInterface' 0 %}#Bru1"> Brunet 1999</a>). Aucun
        consensus n’a été trouvé et une diversité de pratiques continue d’exister en la matière. Il faut
    souligner que pour ceux choisissant la lemmatisation se pose la problématique du choix du lemmatiseur
    puisqu’il en existe de nombreux (TreeTagger<sup><a id="fn13-ref" class="note" href="#fn13">13</a></sup>,
        Cordial<sup><a id="fn14-ref" class="note" href="#fn14">14</a></sup>…). Le choix le plus radical d’une
        racinisation<sup><a id="fn15-ref" class="note" href="#fn15">15</a></sup> peut également être
        envisagé. Enfin, au niveau des mot-outils<sup><a id="fn16-ref" class="note" href="#fn16">16</a></sup>, les
        exclusions peuvent être bien entendu différentes selon les logiciels et les choix des chercheurs
        .</span></p></div>

    <div id="Far1"><p class="mypara"> <span class="marge">	Plusieurs recherches ont déjà traité spécifiquement
    de la question de l’impact de ces prétraitements classiques dans le cas de l’utilisation de plongements
    de mots statiques (méthodes que la partie méthodologique a conduit à privilégier pour cette recherche :
    <em>cf.</em> section <a href="{% url 'EtatDesLieux:home' %}#IV">Chap3.IV</a>). Fares et<em> al.</em> <a
                href="{% url 'Biblio:ViewBiblioInterface' 0 %}#Far1">(2017)</a> obtiennent par exemple de
        meilleurs résultats sur des taches de résolutions d’analogies et de similarités sémantiques après
    lemmatisation. Toutefois il n’existe pas de consensus scientifique autour de la réalisation de ces
    prétraitements. Par exemple, Camacho-Collados <em>et al.</em> <a
                href="{% url 'Biblio:ViewBiblioInterface' 0 %}#Cam1">(2017)</a>
        concluent à une meilleure efficacité d’un simple découpage en « token »
        (unité lexicale) par rapport à l’utilisation de techniques plus complexes comme la lemmatisation ou
    le regroupement des n-grams. La différence avec les conclusions de Fares <em>et al</em>.
        <a href="{% url 'Biblio:ViewBiblioInterface' 0 %}#Far1">(2017)</a>
        précédemment explicitées peut s’expliquer par des expérimentations avec des objectifs
        différents<sup><a id="fn17-ref" class="note" href="#fn17">17</a></sup>. Les spécificités du corpus
        peuvent aussi jouer comme l’indique Camacho-Collados
        <em>et al.</em> <a href="{% url 'Biblio:ViewBiblioInterface' 0 %}#Cam1">(2017)</a> qui nuancent leur
        conclusion
        en affirmant qu’elle ne s’applique selon eux qu’à des textes ne relevant pas de domaine
        spécifique<sup><a id="fn18-ref" class="note" href="#fn18">18</a></sup>.</span></p></div>

    <p class="mypara"> <span class="marge">	Ces lectures m’ont conduit à adopter une position très pragmatique
    consistant à penser que les prétraitements les plus adaptés dépendent avant tout des objectifs fixés et
    des corpus. La théorie et l’état des lieux ne permettent pas de déterminer les prétraitements
    à privilégier. Pour faire face à cette difficulté, j’ai construit à partir du corpus « Article » deux
    corpus : un lemmatisé et un non lemmatisé. Il aurait été certes possible de construire de nombreux
    autres corpus avec tout le panel des prétraitements possibles. Cela n’a pas été réalisé pour des
    raisons de temps. Par conséquent, il n’y a pas eu de recherche expérimentale du meilleur prétraitement
    possible.</span></p>

    <p class="mypara"> <span class="marge">	Le fait de ne pas pouvoir fonder théoriquement le choix des
    prétraitements explique également l’importance prise par le travail précédemment mené sur l’évolution
    lexicale (<em>cf.</em> Manuscrit Chap2.II.5.c). Ce dernier m’avait conduit à faire des
    prétraitements avec des découpages en unités à partir du logiciel <em>Iramuteq</em> (découpage en formes
    graphiques et recomposition des mots composés à partir d’un dictionnaire d’expressions) en optant pour
    la lemmatisation (toujours faite à partir du logiciel <em>Iramuteq</em> qui utilise pour cela un dictionnaire
    mots/lemmes) et en supprimant les mots outils (en ne gardant que les « mots pleins » : noms, verbes,
    adjectifs et adverbes). Ces prétraitements avaient été adoptés essentiellement pour trois raisons
    .</span></p>

    <ul>
    <li>La première relève d’un objectif d’homogénéisation des textes. En
    effet, comme cela a été précédemment explicité dans la partie sur l’amélioration des textes (<em>cf
            .</em> section <a href="{% url 'AmeliorText:home' %}">Chap5</a>), il reste une hétérogénéité liée à des qualités inégales d’océrisation.
    Ces prétraitements permettent de lisser une partie de ces différences. Si la ponctuation et les
    mots-outils sont éliminés, toutes les erreurs liées à ces contenus spécifiques le sont aussi. Cette
    technique permet donc de produire une homogénéisation des textes.</li>

    <li>Le choix de la lemmatisation est aussi lié à une problématique de
    visualisation des résultats. Devant la contrainte de ne pouvoir faire apparaitre qu’un nombre
limité de termes sur une figure, il m’a très souvent semblé plus intéressant de
faire apparaitre des lemmes différents plutôt que
    plusieurs termes pouvant être proches car appartenant au même
        lemme<sup><a id="fn19-ref" class="note" href="#fn19"> 19</a></sup>.
        Cette réflexion explique pourquoi un statut privilégié a été accordé au corpus
    lemmatisé. Le corpus non lemmatisé sert de point de comparaison pour évaluer si les résultats obtenus
    dépendent ou non d’un tel prétraitement.</li>

    <li> Plus spécifiquement, le choix du logiciel <em>IRaMuTeQ</em> avait été effectué après une comparaison avec le
        lemmatiseur <em>TreeTagger</em>. Ce dernier peut être facilement appelé à partir d’un programme <em>Python</em> mais ne peut pas
        être facilement ouvert pour analyser son fonctionnement et corriger des erreurs. À l’opposé, le système de
        dictionnaires<sup><a id="fn20-ref" class="note" href="#fn20">20</a></sup> utilisé par le logiciel
        <em>Iramuteq</em> laisse la possibilité de facilement corriger la lemmatisation si nécessaire. Cette potentialité a
        paru d’autant plus intéressante ici qu’elle permettait de réinvestir une partie du travail sur les
        dictionnaires précédemment réalisé (<em>cf.</em> section <a href="{% url 'AmeliorText:home' %}#V1">Chap5.V.1</a>).</li>
    </ul>


<h4 id="I2b">b) Amélioration des dictionnaires et des prétraitements <a href="#I2b-ref">&#8617;</a> </h4>


    <p class="mypara"> <span class="marge">	Les mots extraits des différents dictionnaires de géographies et
    les noms propres issus du dictionnaire <em>Prolex</em> ont été ajoutés au lexique et aux expressions françaises
    proposés par défaut dans le logiciel <em>Iramuteq</em>. Pour les expressions, ce sont les mots-composés à trait
    d’union qui ont été retenus. Ce choix s’inscrit dans la continuité du dictionnaire proposé par le
    logiciel <em>Iramuteq</em> puisque 92 % des expressions consignées dans ce dictionnaire initial sont des
    mots-composés à trait d’union. À partir des dictionnaires obtenus
        (<a href="{% url 'FinaliseCorpus:DownloadDico' 'IraMotsAmelior1' %}" >@IraMotsLemmesAmelior1</a> et
    <a href="{% url 'FinaliseCorpus:DownloadDico' 'IraExpressionsAmelior1' %}" >@IraExpressionsAmelior1</a>),
        une expérimentation a été réalisée pour voir quelles formes graphiques présentes dans les textes
    n’étaient pas reconnues car absentes des dictionnaires. Ces formes non reconnues ont été ensuite
    classées par ordre décroissant de fréquence. Le résultat obtenu
        (<a href="{% url 'FinaliseCorpus:FNROrderResult' '2' '3' '3' %}" >@FNR1</a>) permet d’identifier
    différents cas de formes non reconnues : des chiffres, des mots coupés malgré le travail réalisé sur
    les fins de ligne, des erreurs d’OCR ou encore des mots existants mais non recensés dans les
    dictionnaires utilisés. Ces identifications ont eu pour conséquence plusieurs actions :</span></p>

    <ul>
    <li>Les dictionnaires ont été complétés pour prendre en compte une
    partie des mots non reconnus et les transformer de manière adéquate en
        lemmes<sup><a id="fn21-ref" class="note" href="#fn21">21</a></sup>.
    Deux nouveaux dictionnaires ont été ainsi obtenus :
        <a href="{% url 'FinaliseCorpus:DownloadDico' 'IraMotsAmelior2' %}" >@IraMotsLemmesAmelior2</a> et
    <a href="{% url 'FinaliseCorpus:DownloadDico' 'IraExpressionsAmelior2' %}" >@IraExpressionsAmelior2</a>.
        La possibilité d’ajouter des dictionnaires enrichis mots/lemmes et d’expressions a été
    implémentée dans l’application.</li>

    <li>Une liste de « fin de mots » a été établie pour essayer de
    reconstituer une partie des termes coupés. En effet, à partir du recensement précédent des formes non
    reconnues, il est assez facile de déterminer celles correspondant à des fins de
        mots<sup><a id="fn22-ref" class="note" href="#fn22">22</a></sup>. La liste ainsi construite
        (<a href="{% url 'FinaliseCorpus:DownloadDico' 'FinMot1' %}" >@FinMots1</a>) peut être ensuite
    facilement utilisée pour reconstituer les mots avant la reconnaissance des expressions et la
    lemmatisation. Dans l’établissement de cette liste de « fin de mots », l’objectif a été de sélectionner
    des formes n’étant pas également des mots pour ne pas créer des agrégations erronées. La seule
    exception qui a été réalisée correspond à la forme « ment ». En effet, celle dernière peut renvoyer au
    verbe « mentir » conjugué. Toutefois, l’examen des textes a montré que la majorité des cas correspond à
    la fin d’un adverbe coupé. Cette forme a été par conséquent intégrée à la liste de « fin de mots » même
    si elle peut provoquer quelques agrégations
        erronées<sup><a id="fn23-ref" class="note" href="#fn23">23</a></sup>.</li>

    <li>Au niveau des quelques erreurs d’OCR qui apparaissent dans les formes non
reconnues les plus fréquentes, il est possible d’en corriger une
    grande partie par l’ajout de la forme corrigée dans le
        dictionnaire<sup><a id="fn24-ref" class="note" href="#fn24">24</a></sup>.</li>

    <li>Enfin, le choix d’exclure les chiffres dans les textes finaux à
    analyser a été retenu car il a été considéré que ceux-ci ont un intérêt mineur par rapport à la
    recherche menée.</li>
        </ul>


    <p class="mypara"> <span class="marge">	Une fois ces décisions prises et ces actions réalisées,
    l’application pour réaliser ces prétraitements a été construite.</span></p>


<h4 id="I2c">c) Réalisation et limite des prétraitements effectués <a href="#I2c-ref">&#8617;</a> </h4>


    <p class="mypara"> <span class="marge">	En plus du choix des dictionnaires (mots/lemmes, expression) et de la liste de « fin de
mots », l’application permet de choisir d’effectuer (ou non) un premier ensemble de
transformations. Les textes sont alors convertis entièrement en minuscule. Les caractères
non conventionnels sont enlevés. La liste de « fin de mots » est utilisée pour reconstituer les
mots coupés. Les expressions sont identifiées à l’aide du dictionnaire correspondant.</span></p>

      <p class="mypara"> <span class="marge">Le second grand
    choix que permet l’application porte sur la réalisation (ou non) de la lemmatisation. Concernant le
    corpus d’articles non lemmatisés, intitulé « ArticleNonLem », le choix réalisé a été d’effectuer tout
    de même le premier ensemble de transformation. La différence avec le corpus d’articles lemmatisés,
    intitulé « ArticleLem » porte ainsi que sur la
    lemmatisation<sup><a id="fn25-ref" class="note" href="#fn25">25</a></sup>. Les options utilisées pour
        la construction
    de chaque corpus sont accessibles dans l’interface à partir des liens suivants :
        <a href="{% url 'FinaliseCorpus:CorpusFinVisualise' 'ArticleLem' %}" >@ArticleLem</a>,
        <a href="{% url 'FinaliseCorpus:CorpusFinVisualise' 'ArticleNonLem' %}" >@ArticleNonLem</a> et
        <a href="{% url 'FinaliseCorpus:CorpusFinVisualise' 'ArticlePlusCrLem' %}" >@ArticlePlusCrLem</a>.
</span></p>

    <p class="mypara"> <span class="marge">	Par rapport à la lemmatisation, il faut reconnaître que la méthode
    utilisée par le logiciel <em>IRaMuTeQ</em> n’est pas optimale du fait du mécanisme assez basique de dictionnaire
    qui attribue un lemme à un mot sans tenir compte du contexte. Par exemple, le mot « porte » peut
    renvoyer au lemme « porte » correspond au nom commun correspondant, mais aussi au lemme « porter »
    suivant les situations. Le fonctionnement du logiciel <em>IRaMuTeQ</em> privilégie une seule solution, toujours
    la même, ce qui engendre inévitablement quelques erreurs. Il n’y a pas eu d’amélioration implémentée
    pour faire face à ce problème pour des raisons de temps. Il s’agit évidemment d’un axe d’amélioration
    possible par rapport au travail mené dans le cadre de cette thèse. Comme cela a été précédemment dit,
    la solution adoptée n’a pas la prétention d’être optimale. Sa simplicité a permis de produire des
    améliorations mais ces dernières restent limitées.</span></p>

    <p class="mypara"> <span class="marge">	Suite à cette étape, les corpus définitifs sont construits. Une
        évaluation a été alors effectuée pour avoir un aperçu plus précis de la qualité des données
    utilisées.</span></p>


<h2 id="II">II) Évaluation des corpus d’étude <a href="#II-ref">&#8617;</a> </h2>


    <p class="mypara"> <span class="marge">	Pour chaque corpus, une méthode automatique de sélection au hasard
    de 20 documents, puis de 100 formes<sup><a id="fn26-ref" class="note" href="#fn26">26</a></sup>
        consécutives pour
    chacun de ces documents, a été mise en place. Ces quantités, 20 et 100, n’ont pas été déterminées à la
    suite d’un calcul pour construire un échantillon représentatif. Elles résultent plutôt de l’objectif de
    réaliser ces évaluations dans un temps raisonnable. Par rapport à la taille des corpus obtenus
    (« ArticleLem » : 3223 textes et 10 280 408 lemmes, « ArticleNonLem » : 3223 textes et 19 619 153 mots
    et formes de ponctuations, « ArticlePlusCrLem » : 9701 textes et 14 453 978 lemmes), les parties
    évaluées peuvent être considérées comme assez réduites. En effet, s’il m’a semblé nécessaire de
    réaliser une évaluation pour chaque corpus, il ne m’a pas semblé indispensable de réaliser un travail
    exhaustif sur ce sujet. Au-delà du problème du temps disponible et des priorités qu’il est nécessaire
    de fixer dans tout travail de recherche, ce choix s’explique aussi par la multiplicité des mesures
    possible pour une telle évaluation.</span></p>

    <p class="mypara"> <span class="marge">	Le fait de reconnaître qu’il s’agit d’une évaluation réduite permet
    de mieux justifier l’utilisation d’une seule mesure : le taux d’erreur de mots
        (WER<sup><a id="fn27-ref" class="note" href="#fn27">27</a></sup>).
        Le taux d’erreur de caractères (CER<sup><a id="fn28-ref" class="note" href="#fn28">28</a></sup>) qui
    est souvent aussi mis en avant pour évaluer des systèmes d’OCR (Margner, 2018) n’a pas été retenu. Ce
    choix s’explique par la finalité de cette recherche. Les évolutions sémantiques, qu’il s’agit de
    caractériser, se jouent à l’échelle des mots (ou lemmes) et non des caractères. Par conséquent, une
    mesure prenant comme référence cette unité de base du mot (ou du lemme suivant les corpus) a été
    privilégiée.</span></p>

 <p class="mypara"> <span class="marge">Le taux d’erreur de mots est défini par la formule suivante :</span></p>


<p class="mypara"> <span class="marge">WER=
(S+D+I) /N
</span></p>


    <p class="mypara"> <span class="marge">Où S est le nombre de substitutions (mots incorrectement reconnus),
    D est le nombre de suppressions (mots omis) et I le nombre d’insertions (mots ajoutés) par rapport à un
    texte de référence (constitué de N mots). Les textes de référence sont constitués en réalisant
    l’ensemble du travail d’amélioration manuellement. Plus le taux d’erreur de mots est proche de 0, plus
    les textes évalués sont considérés de qualité.</span></p>


    <p class="mypara"> <span class="marge">	Les résultats obtenus pour chaque corpus sont les suivants :</span></p>


<table>
<tr>
<td></td>
<td>Substitutions</td>
<td>Suppressions</td>
<td>Insertions</td>
<td>Nombre de mots<br>
du texte de référence</td>
<td>WER</td>
</tr>
<tr>
<td>ArticleLem</td>
<td>64</td>
<td>54</td>
<td>36</td>
<td>2027</td>
<td>0,08</td>
</tr>
<tr>
<td>ArticleNonLem</td>
<td>35</td>
<td>127</td>
<td>36</td>
<td>2093</td>
<td>0,09</td>
</tr>
<tr>
<td>ArticlePlusCrLem</td>
<td>56</td>
<td>75</td>
<td>23</td>
<td>2052</td>
<td>0,08</td>
</tr>
</table>


<div class="a" id="Tableau4" >Tableau n°4 : Calcul du taux d’erreur de mots (WER) pour chaque corpus</div>

<br>
    <p class="mypara"> <span class="marge">Les taux d’erreur de mots obtenus pour les trois corpus sont
        très proches. Globalement, il existe moins d’une erreur (substitution, suppression ou insertion)
        toutes les dix formes évaluées. La qualité un peu supérieure en valeur absolue des corpus
        lemmatisés provient d’un nombre moindre de mots omis (suppression). En effet, plusieurs documents
        non lemmatisés présentent plusieurs formes de ponctuation ou/et des petits articles (à, de, l’…)
        oubliés par l’OCR. Dans le détail<sup><a id="fn29-ref" class="note" href="#fn29">29</a></sup>. La qualité un peu
        supérieure en valeur absolue
    des corpus lemmatisés provient d’un nombre moindre de mots omis (suppression). En effet, plusieurs
    documents non lemmatisés présentent plusieurs formes de ponctuation ou des petits articles (à, de, l’…)
    oubliés par l’OCR. Dans le détail<sup><a id="fn30-ref" class="note" href="#fn30">30</a></sup>,
        il y a une certaine hétérogénéité entre des textes sans
erreur (ou presque) et d’autres qui peuvent présenter jusqu’à deux fois plus d’erreurs que la
moyenne. La lemmatisation permet de réduire une partie de cette hétérogénéité en
supprimant la ponctuation et ces petits articles. Toutefois, elle est à l’origine aussi de
nouvelles erreurs.</span></p>

    <p class="mypara"> <span class="marge">	Une quantification des causes d’erreurs a été réalisée. Trois
    causes principales ont été identifiées :
        délimitation<sup><a id="fn31-ref" class="note" href="#fn31">31</a></sup>,
    océrisation, lemmatisation, Une catégorie « autre » a été ajoutée pour prendre en compte des cas non
    attendus.</span></p>


<table>
<tr>
<td></td>
<td>Délimitation</td>
<td>Océrisation</td>
<td>Lemmatisation</td>
<td>Autre</td>
</tr>
<tr>
<td>ArticleLem</td>
<td>26</td>
<td>30</td>
<td>95</td>
<td>2</td>
</tr>
<tr>
<td>ArticleNonLem</td>
<td>38</td>
<td>157</td>
<td>0</td>
<td>3</td>
</tr>
<tr>
<td>ArticlePlusCrLem</td>
<td>4</td>
<td>29</td>
<td>106</td>
<td>14</td>
</tr>
</table>


<div class="a" id="Tableau5" >Tableau n°5 : Causes des erreurs détectées pour chaque corpus</div>
<br>

    <p class="mypara"> <span class="marge">	Les erreurs de délimitation sont essentiellement dues à deux
    raisons. La première est liée à des légendes de figures qui sont situées sous l’image après le titre et
    qui n’ont pas été intégrées dans les fenêtres graphiques tracées par l’UAR <em>Persée</em>. Elles se
    retrouvent alors dans les textes à analyser. Ceci est d’autant plus gênant qu’il y a une hétérogénéité
    de traitement par rapport à des figures où la légende se trouve dans les fenêtres graphiques tracées
    par l’UAR <em>Persée</em>. Ce problème n’est pas simple à résoudre car il nécessite de mettre au point
    des méthodes de détection automatique des légendes. Une deuxième cause des erreurs de délimitation
    identifiées lors des évaluations menées provient de hauts de page non reconnus. Il s’agit de trois cas
    sur l’ensemble des documents analysés. La méthode mise au point n’est pas parfaite mais elle fonctionne
    tout de même de manière satisfaisante comme le montre aussi plusieurs retraits réussis de hauts de page
    sur les passages évalués.</span></p>

    <p class="mypara"> <span class="marge">	Les erreurs d’océrisation concernent surtout la ponctuation et des
    petits articles comme le montre la différence entre les corpus lemmatisés et non lemmatisés. La
    reconstitution des mots coupés en fin de phrase n’est pas parfaite mais permet de corriger plusieurs
    erreurs sur les passages évalués. Si l’opération de lemmatisation réduit l’hétérogénéité des documents
    par rapport aux erreurs d’océrisation, elle ne la supprime pas. Ces erreurs d’océrisation ont un impact
    sur les erreurs de lemmatisation qu’elles tendent à augmenter.</span></p>

    <p class="mypara"> <span class="marge">	Par rapport à ces dernières, plusieurs cas doivent être distingués.
    Il y a tout d’abord un grand nombre d’erreurs de lemmatisation liées aux formes non reconnues. Si le
    texte présente des mots peu fréquents et mal référencés dans les dictionnaires utilisés, il y a alors
    beaucoup de fautes de lemmatisation. L’importance de ces erreurs peut être relativisée en pensant que
    par rapport à la problématique de détection de changement sémantique majeur, ces mots rares jouent un
    rôle assez secondaire. Quelques erreurs de lemmatisation apparaissent toutefois comme problématique.
    Par exemple, quand le terme « sens » est transformé en verbe « sentir » alors qu’il est utilisé dans sa
    forme nominale. Même si la lemmatisation a été
    déjà été reconnue comme imparfaite, cette évaluation vient confirmer qu’il s’agit d’un important axe
    d’amélioration par rapport au travail effectué.</span></p>

    <div id="ArticlePlusCrLem2"><p class="mypara"> <span class="marge">	Enfin, la catégorie
    « Autre » présente un score plus élevé pour le
    corpus avec les comptes-rendus. L’explication réside dans la découverte de répétitions de lemmes
    provenant de termes dans une balise dans le format « XML-TEI » qui n’avaient pas été pris en compte
    lors de l’extraction des mots. Il a été décidé pour rendre ce corpus de comparaison plus valide de
    construire un corpus « ArticlePlusCrLem2 » en retirant seulement ces répétitions
        erronées<sup><a id="fn32-ref" class="note" href="#fn32">32</a></sup>.</span></p></div>

<h2 id="III">III) Réflexions conclusives <a href="#III-ref">&#8617;</a> </h2>

    <p class="mypara"> <span class="marge">	Cette évaluation marque la fin de cette première partie qui a permis de
        choisir une orientation méthodologique (les plongements de mots non contextualisés) et de préparer les données
        aux analyses envisagées. Au-delà de ces résultats pratiques, c’est ma conception même du travail de « préparation
        des données » qui a évolué. Le fait de se servir des difficultés rencontrées pour commencer à développer une
        critique des sources est, à mon sens, l’apport le plus important de cette partie</span></p>

    <p class="mypara"> <span class="marge"> De plus, en développant de manière approfondie ces deux plans (méthodes et
        données), il s’est produit, dans les deux cas, le développement d’un phénomène ambivalent : d’un côté, l’acquisition
        d’une certaine force, d’une certaine assise au sens où cette recherche peut se réfléchir et faire valoir une
        connaissance approfondie (aussi bien des données utilisées que du spectre de méthodes possibles par rapport à la
        problématique retenue). De l’autre, la reconnaissance évidente d’une certaine fragilité, au sens où les choix
        réalisés se doivent de reconnaitre leurs limites : les données sont imparfaites et même si les résultats de l’OCR
        étaient optimaux, certains choix de délimitations du corpus (intégration ou non des comptes-rendus, prise en compte
        des titres de figures…) n’ont pas de justifications fortes.</span></p>

    <p class="mypara"> <span class="marge"> Par rapport à cette ambivalence, il me semble possible de mettre en avant tout
        autant la rupture que le maintien d’un réalisme. En effet, en reconnaissant que les données et les méthodes sont
        imparfaites, il existe évidemment une rupture avec un réalisme fort. Dans le même temps, tout ce travail réalisé
        pour l’amélioration des données et pour choisir la méthode plus appropriée a pour objectif que les résultats ne
        soient pas des fictions mais permettent un discours fondé empiriquement c’est-à-dire renvoyant à une forme de réalisme.</span></p>

    <p class="mypara"> <span class="marge">Cette idée qui a trait à la problématique d’Olivier Orain, est ici simplement
        esquissée et méritera ultérieurement des développements plus amples. Avant cela, nous nous engageons à partir des
        données précédemment obtenues et de la piste méthodologique retenue dans la production de résultats et leurs analyses.</span></p>



<!-- NOTE DEB -->

<p class="present">Notes du chapitre</p>

<p id="fn1">[1] Ce premier fichier forme le corpus additionnel nommé « ArticleAdd ». Il est constitué des articles suivants :
    <a href ="https://analytics.huma-num.fr/EtPistezMots/finalise/VisualiseCorpusAdd/ArticleAdd">@ArticleAdd</a>
<a href="#fn1-ref">&#8617;</a></p>
<p id="fn2">[2] Ce deuxième fichier forme le corpus additionnel nommé « ArticlePlusCrAdd ». Il est constitué des articles et comptes-rendus suivants :
    <a href ="https://analytics.huma-num.fr/EtPistezMots/finalise/VisualiseCorpusAdd/ArticlePlusCrAdd">@AriclePlusCrAdd</a>
<a href="#fn2-ref">&#8617;</a></p>
<p id="fn3">[3] Ces corrections manuelles sont dues à la difficulté rencontrée pour scanner correctement du
    fait des reliures. Les textes proches de cette dernière tendent à être mal reconnus ensuite par l’OCR.
    L’UAR Persée découpe les revues scannées pour faire face à cette difficulté. Cette action n’était pas
    envisageable dans le cadre de mon travail.
<a href="#fn3-ref">&#8617;</a></p>
<p id="fn4">[4] Avec notamment la volonté de ne sélectionner des textes en fonction d’auteurs spécifiques.
<a href="#fn4-ref">&#8617;</a></p>
    <p id="fn5">[5] <a href ="https://pypi.org/project/langdetect/" target="_blank">https://pypi.org/project/langdetect/</a>
<a href="#fn5-ref">&#8617;</a></p>
<p id="fn6">[6] Les choix réalisés dans l’interface peuvent être consultés pour ces deux corpus avec les liens suivants :
    <a href ="https://analytics.huma-num.fr/EtPistezMots/finalise/VisualiseCorpusComplet/ArticleComplet">@ArticleComplet</a> et
    <a href ="https://analytics.huma-num.fr/EtPistezMots/finalise/VisualiseCorpusComplet/ArticlePlusCrComplet">@ArticlePlusCrComple</a>t
<a href="#fn6-ref">&#8617;</a></p>
<p id="fn7">[7] « Aujourd’hui » est un mot composé de deux formes graphiques.
<a href="#fn7-ref">&#8617;</a></p>
<p id="fn8">[8]  « Aujourd’hui » est un cas de mot composé à apostrophe.
<a href="#fn8-ref">&#8617;</a></p>
<p id="fn9">[9] « Après-midi » est un cas de mot composé à trait d’union.
<a href="#fn9-ref">&#8617;</a></p>
<p id="fn10">[10] « Pomme de terre » est un cas de mot composé détaché. La limite est alors assez
    subjective entre un simple syntagme et un mot composé. Par exemple, « carte géographique » est-il un
    mot composé ?
<a href="#fn10-ref">&#8617;</a></p>
<p id="fn11">[11] Une séquence continue de n-mots.
<a href="#fn11-ref">&#8617;</a></p>
<p id="fn12">[12] La lemmatisation consiste à transformer chaque forme en un lemme qui est le plus souvent
    la «  forme canonique » enregistrée dans le dictionnaire. Par exemple, la forme « espaces » est
    transformé par le lemme « espace ». La forme « allons » en verbes « aller ». Ainsi, plusieurs formes,
    dites fléchies, existe pour un même lemme.
<a href="#fn12-ref">&#8617;</a></p>
<p id="fn13">[13] <a href ="https://cis.uni-muenchen.de/~schmid/tools/TreeTagger/" target="_blank">https://cis.uni-muenchen.de/~schmid/tools/TreeTagger/</a>
    qui est intégré notamment au logiciel TXM.
<a href="#fn13-ref">&#8617;</a></p>
<p id="fn14">[14] <a href ="https://www.atala.org/content/cordial-universit%C3%A9s-ou-cordial-analyseur" target="_blank">https://www.atala.org/content/cordial-universit%C3%A9s-ou-cordial-analyseur</a>
    qui est intégré au
    logiciel Hyperbase.
<a href="#fn14-ref">&#8617;</a></p>
<p id="fn15">[15] Chaque terme est transformé en sa racine. Par exemple, le verbe « chercher » en
    « cherch ». Le nom « chercheur » est également transformé en « cherch » à la différence de la
    lemmatisation qui maintient une différence entre ces deux termes.
<a href="#fn15-ref">&#8617;</a></p>
<p id="fn16">[16] Un mot outil est un mot dont le rôle sémantique est secondaire. Son rôle est avant tout
    syntaxique. C’est le cas par exemple de la majorité des prépositions, conjonctions, pronoms et
    déterminants.
<a href="#fn16-ref">&#8617;</a></p>
    <p id="fn17">[17] Catégorisation de textes et analyse de sentiments pour Camacho-Collados <em>et al.</em>
        (2017) / Résolutions d’analogies et de similarités sémantiques pour Fares <em>et al.</em> (2017)
<a href="#fn17-ref">&#8617;</a></p>
    <p id="fn18">[18] Camacho-Collados <em>et al.</em> (2017) citent l’exemple d’un corpus de textes relevant du
    domaine médical sur lequel une lemmatisation et un regroupement en n-gram est plus efficace qu’un simple
    découpage en « token ».
<a href="#fn18-ref">&#8617;</a></p>
<p id="fn19">[19] Par exemple, constater qu’« espace » et « espaces » sont proches sur une AFC a été jugé
    d’un intérêt moindre par rapport au fait de pouvoir compléter la figure par un autre lemme.
<a href="#fn19-ref">&#8617;</a></p>
<p id="fn20">[20] Dictionnaire mots/lemmes et dictionnaire d’expressions.
<a href="#fn20-ref">&#8617;</a></p>
<p id="fn21">[21] Ce travail a été effectué jusqu’aux formes non reconnues apparaissant au moins 15 fois dans l’ensemble du corpus « ArticleComplet ».
<a href="#fn21-ref">&#8617;</a></p>
<p id="fn22">[22] La forme non reconnue « tions » par exemple est une fin de mot puisqu’il n’existe pas en français de terme correspondant à cette forme.
<a href="#fn22-ref">&#8617;</a></p>
<p id="fn23">[23] Par exemple, une phrase comme « La carte ment » est automatiquement transformé en « La cartement »
<a href="#fn23-ref">&#8617;</a></p>
<p id="fn24">[24] Par exemple, si le premier accent d’épistémologie est souvent mal reconnu, il suffit
    d’ajouter une forme « epistémologie » qui renvoie au lemme « épistémologie ».
<a href="#fn24-ref">&#8617;</a></p>
<p id="fn25">[25] Dans le cas de cette recherche, la lemmatisation implique aussi l’enlèvement des
    mots-outils (pronoms, prépositions, articles, conjonctions…) et des formes non reconnues.
<a href="#fn25-ref">&#8617;</a></p>
<p id="fn26">[26] Mots, expressions et ponctuations pour les corpus non lemmatisés. Lemmes et expressions pour les corpus lemmatisés.
<a href="#fn26-ref">&#8617;</a></p>
<p id="fn27">[27] « Word Error Rate » en anglais.
<a href="#fn27-ref">&#8617;</a></p>
<p id="fn28">[28] « Caracter Error Rate » en anglais.
<a href="#fn28-ref">&#8617;</a></p>
<p id="fn29">[29] La prudence de cette formulation est liée à la taille réduite des échantillons analysés.
<a href="#fn29-ref">&#8617;</a></p>
<p id="fn30">[30] Les évaluations détaillées sont consultables à partir des liens suivants :
    <a href ="https://analytics.huma-num.fr/EtPistezMots/evaluate/SelectEchantillonEvaluate/ArticleLem/20/100/1">@ArticleLemEval1</a>,
    <a href ="https://analytics.huma-num.fr/EtPistezMots/evaluate/SelectEchantillonEvaluate/ArticleNonLem/20/100/1">@ArticleNonLemEval1</a> et
    <a href ="https://analytics.huma-num.fr/EtPistezMots/evaluate/SelectEchantillonEvaluate/ArticlePlusCrLem/20/100/1">@ArticlePlusCrLemEval1</a>.
    Le dernier item pour chaque passage est un lien permettant de consulter l’évaluation détaillée du passage en question.
<a href="#fn30-ref">&#8617;</a></p>
<p id="fn31">[31] La délimitation renvoie au fait que des parties de textes peuvent être présentes alors
    qu’elles ne devraient pas l’être (ou inversement). Par exemple, si le retrait automatique des
    publicités, des hauts de pages, des bas de pages a échoué, les parties correspondantes sont liées à des
    erreurs de délimitation. Cette erreur peut aussi toucher des documents entiers si ces derniers se
    révèlent être dans un corpus alors qu’il ne devrait pas.
<a href="#fn31-ref">&#8617;</a></p>
<p id="fn32">[32] La fonction « CreateCorpusArticlePlusCrNonLem2 » dans
    «  AllApps/PreTraitement/Persee/EvaluateCorpus/view.py » permet de réaliser la construction de ce
    corpus à partir du corpus « ArticlePlusCrLem ».
<a href="#fn32-ref">&#8617;</a></p>


<!-- NOTE FIN -->
<br>

<p class="suite"> Suite :
    <a  href="{% url 'TxtTheseConstructResult:home' %}">PartII.Chap7) Construction des résultats,
        analyses et discussions</a>
<p class="suite"> Retour :
    <a  href="{% url 'general:home' %}">Page d'accueil</a>
</p>




<script src="{% static 'Introduction/js/ArrAvt.js' %}" type="text/javascript"
                charset="utf-8"></script>
<script type="text/javascript">
 EnArrEnAvt("{% url 'AmeliorText:home' %}", "{% url 'TxtTheseConstructResult:home' %}");
</script>


</body>
</html>